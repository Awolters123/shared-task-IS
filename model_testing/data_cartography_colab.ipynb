{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: models.py [-h] [-d1 DATA_FILE1] [-t TEST_FILE] [-tn TEST_NAME] [--easy] [-d3 DATA_FILE3] [-d4 DATA_FILE4] [--semeval] [--max_len] [-d2 DATA_FILE2] [-m MODE] [--gab_only]\n",
    "#                  [--task_b] [-tf TRANSFORMER] [-lr LEARN_RATE] [-bs BATCH_SIZE] [-sl SEQUENCE_LENGTH] [-epoch EPOCHS] [--no_weight_restore] [--save_model SAVE_MODEL]\n",
    "\n",
    "# options:\n",
    "#   -h, --help            show this help message and exit\n",
    "#   -d1 DATA_FILE1, --data_file1 DATA_FILE1\n",
    "#                         Dataset to train the model with, default is the SemEval 2022 sexism dataset\n",
    "#   -t TEST_FILE, --test_file TEST_FILE\n",
    "#                         Test file, which will be used to evaluate the model\n",
    "#   -tn TEST_NAME, --test_name TEST_NAME\n",
    "#                         Test file name, which will be used to store multiple test files.\n",
    "# \n",
    "#   --easy                Run the model using easy-to-learn data.\n",
    "#   -d3 DATA_FILE3, --data_file3 DATA_FILE3\n",
    "#                         Easy-to-learn train data from data cartography\n",
    "#   -d4 DATA_FILE4, --data_file4 DATA_FILE4\n",
    "#                         Easy-to-learn dev data from data cartography\n",
    "#   --semeval             Run the model for task A, using the semeval dataset.\n",
    "#   --max_len             Run the model using max padding length based on input.\n",
    "# \n",
    "#   -d2 DATA_FILE2, --data_file2 DATA_FILE2\n",
    "#                         Extra dataset to train the model with, has to have compatible labels with the first dataset\n",
    "#   -m MODE, --mode MODE  This argument sets the data merge option, you can choose between concatenating (concat) or shuffling (shuffle), default is concat\n",
    "#   --gab_only            Run the model using only gab added data.\n",
    "# \n",
    "#   --task_b              Run the model for task B, using the extra EXIST dataset\n",
    "# \n",
    "#   -tf TRANSFORMER, --transformer TRANSFORMER\n",
    "#                         this argument takes the pretrained language model link from HuggingFace, default is HateBERT\n",
    "#   -lr LEARN_RATE, --learn_rate LEARN_RATE\n",
    "#                         Set a custom learn rate for the pretrained language model, default is 5e-5\n",
    "#   -bs BATCH_SIZE, --batch_size BATCH_SIZE\n",
    "#                         Set a custom batch size for the pretrained language model, default is 8\n",
    "#   -sl SEQUENCE_LENGTH, --sequence_length SEQUENCE_LENGTH\n",
    "#                         Set a custom maximum sequence length for the pretrained language model, default is 100\n",
    "#   -epoch EPOCHS, --epochs EPOCHS\n",
    "#                         This argument selects the amount of epochs to run the model with, default is 1 epoch\n",
    "#   --no_weight_restore   Run the model without weight restore\n",
    "# \n",
    "#   --save_model SAVE_MODEL\n",
    "#                         Save the current model to a file for later use on a test file, requires a name to be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data_cartography, currently the parameter '--easy' makes sure that it can import the .tsv outputs from the cartography folders, \n",
    "# if you want to use those, make sure that you link to the right files with d3 (train) and d4 (dev) (dev is not really needed, but that input is a leftover from before it was realized\n",
    "# that this was not needed)\n",
    "# Make sure to replace all filenames and directories so it coresponds with your local folder structure!\n",
    "\n",
    "!python models.py \\\n",
    "\t-tf GroNLP/hateBERT \\\n",
    "\t--mode shuffle \\\n",
    "\t--learn_rate 1e-5 \\\n",
    "\t--batch_size 16 \\\n",
    "\t--sequence_length 325 \\\n",
    "\t--epochs 10 \\\n",
    "\t-d1 data/train_all_tasks.csv \\\n",
    "\t-d2 data/EXIST2021_merged.csv \\\n",
    "\t--test_file dev_task_a_entries.csv \\\n",
    "\t--test_name job_hate_taska_16_1e5_325_shuffle \\\n",
    "\t-d3 data/easy-to-learn/hatebert/shuffle/train.tsv \\\n",
    "\t-d4 data/easy-to-learn/hatebert/shuffle/dev.tsv \\\n",
    "\t--easy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86d0237a3a54a747ea5eeadf5a7aab3e7ee246c76033eca4ace7d99a07ef554b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
