{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "fS4VLPmVqAFW"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read csv file\n",
        "df = pd.read_csv('train_all_tasks.csv')"
      ],
      "metadata": {
        "id": "x6wEA4CbLJqK"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data pre-processing"
      ],
      "metadata": {
        "id": "NcxJg7MiK2CC"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text and labels for task A\n",
        "xtrain_taskA, xdev_taskA, ytrain_taskA, ydev_taskA = train_test_split(df['text'], df['label_sexist'], test_size=0.2, random_state=10)\n",
        "\n",
        "# text and labels for task B\n",
        "xtrain_taskB, xdev_taskB, ytrain_taskB, ydev_taskB = train_test_split(df['text'], df['label_category'], test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "eOHBK8Eak6Ck"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(ytrain_taskA))\n",
        "print(Counter(ydev_taskA))\n",
        "\n",
        "print(Counter(ytrain_taskB))\n",
        "print(Counter(ydev_taskB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-kdz_GIlOI1",
        "outputId": "e0b0cabb-06ac-44b5-c420-555c56b38167"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'not sexist': 8496, 'sexist': 2704})\n",
            "Counter({'not sexist': 2106, 'sexist': 694})\n",
            "Counter({'none': 8496, '2. derogation': 1279, '3. animosity': 912, '4. prejudiced discussions': 258, '1. threats, plans to harm and incitement': 255})\n",
            "Counter({'none': 2106, '2. derogation': 311, '3. animosity': 253, '4. prejudiced discussions': 75, '1. threats, plans to harm and incitement': 55})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels_taskA(labels):\n",
        "    \"\"\"Encoding the labels to numerical values\"\"\"\n",
        "    y_label = []\n",
        "    for label in labels:\n",
        "        if label == \"not sexist\":\n",
        "            y_label.append(0)\n",
        "        elif label == \"sexist\":\n",
        "            y_label.append(1)\n",
        "    return np.array(y_label)"
      ],
      "metadata": {
        "id": "Lp2RTy8qsVlG"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels_taskB(labels):\n",
        "    \"\"\"Encoding the labels to numerical values\"\"\"\n",
        "    y_label = []\n",
        "    for label in labels:\n",
        "        if label == \"none\":\n",
        "            y_label.append(0)\n",
        "        elif label == \"1. threats, plans to harm and incitement\":\n",
        "            y_label.append(1)\n",
        "        elif label == \"2. derogation\":\n",
        "            y_label.append(2)\n",
        "        elif label == \"3. animosity\":\n",
        "            y_label.append(3)\n",
        "        elif label == \"4. prejudiced discussions\":\n",
        "            y_label.append(4)\n",
        "    return np.array(y_label)"
      ],
      "metadata": {
        "id": "K9hcW7Px15tG"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_train(xtrain, ytrain, xdev, ydev):\n",
        "  model = SVC(kernel='linear')\n",
        "  vec = CountVectorizer()\n",
        "\n",
        "  vec.fit(xtrain, xdev)\n",
        "  xtrain_enc = vec.transform(xtrain)\n",
        "  xdev_enc = vec.transform(xdev)\n",
        "\n",
        "  model.fit(xtrain_enc, ytrain)\n",
        "  pred = model.predict(xdev_enc)\n",
        "  print(\"Classification Report:\\n{0}\\nConfusion Matrix:\\n{1}\".format(classification_report(ydev, pred), confusion_matrix(ydev, pred)))"
      ],
      "metadata": {
        "id": "AV63GRplhAY0"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Running Task A (Binary) "
      ],
      "metadata": {
        "id": "wi1IsbCCc_Dt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_taskA = encode_labels_taskA(ytrain_taskA)\n",
        "ydev_taskA = encode_labels_taskA(ydev_taskA)"
      ],
      "metadata": {
        "id": "LrIGCBzjiYdG"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_train(xtrain_taskA, ytrain_taskA, xdev_taskA, ydev_taskA)"
      ],
      "metadata": {
        "id": "fxXmSsyUs80u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f663a422-1a2b-46f8-aa0a-8c05f20aebac"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87      2106\n",
            "           1       0.60      0.53      0.56       694\n",
            "\n",
            "    accuracy                           0.80      2800\n",
            "   macro avg       0.72      0.71      0.71      2800\n",
            "weighted avg       0.79      0.80      0.79      2800\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1857  249]\n",
            " [ 324  370]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Running Task B (Multi-class) "
      ],
      "metadata": {
        "id": "I5jrr_35dAKE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_taskB = encode_labels_taskB(ytrain_taskB)\n",
        "ydev_taskB = encode_labels_taskB(ydev_taskB)"
      ],
      "metadata": {
        "id": "NGkqZZfF9x8U"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_train(xtrain_taskB, ytrain_taskB, xdev_taskB, ydev_taskB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8faSPLLj0Tl",
        "outputId": "81f3479a-e0a0-4310-ffdc-5abb88f6d34f"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88      2106\n",
            "           1       0.21      0.16      0.18        55\n",
            "           2       0.36      0.34      0.35       311\n",
            "           3       0.40      0.25      0.30       253\n",
            "           4       0.22      0.11      0.14        75\n",
            "\n",
            "    accuracy                           0.75      2800\n",
            "   macro avg       0.41      0.35      0.37      2800\n",
            "weighted avg       0.72      0.75      0.74      2800\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1926   18  101   47   14]\n",
            " [  35    9    6    4    1]\n",
            " [ 147   10  107   36   11]\n",
            " [ 110    6   72   62    3]\n",
            " [  50    0   11    6    8]]\n"
          ]
        }
      ]
    }
  ]
}